{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK classifiers work with featstructs (http://www.nltk.org/_modules/nltk/featstruct.html). \n",
    "\n",
    "For more information about how Naive Bayes works in NLTK, please see here: http://www.nltk.org/_modules/nltk/classify/naivebayes.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will construct a very simple dictionary which maps a feature name (word) to True if the word exists in the data. We will not use bag of words for this example because, for sentiment classification, whether a word occurs or not seems to matter more than its frequency. When it comes to Naive Bayes, this is called binary multinomial Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie reviews corpus has 1000 positive files and 1000 negative files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the classifier, we initially need to creat feature-label pairs where the features will be a feature dictionary in the form of {word: True} and the label is either a \"pos\" or a \"neg\" label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "negreviews = [(extract_word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posreviews = [(extract_word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, a feature-label pair could be: ({'\"': True, 'around': True,..., 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'the': True,\n",
       "  'happy': True,\n",
       "  'bastard': True,\n",
       "  \"'\": True,\n",
       "  's': True,\n",
       "  'quick': True,\n",
       "  'movie': True,\n",
       "  'review': True,\n",
       "  'damn': True,\n",
       "  'that': True,\n",
       "  'y2k': True,\n",
       "  'bug': True,\n",
       "  '.': True,\n",
       "  'it': True,\n",
       "  'got': True,\n",
       "  'a': True,\n",
       "  'head': True,\n",
       "  'start': True,\n",
       "  'in': True,\n",
       "  'this': True,\n",
       "  'starring': True,\n",
       "  'jamie': True,\n",
       "  'lee': True,\n",
       "  'curtis': True,\n",
       "  'and': True,\n",
       "  'another': True,\n",
       "  'baldwin': True,\n",
       "  'brother': True,\n",
       "  '(': True,\n",
       "  'william': True,\n",
       "  'time': True,\n",
       "  ')': True,\n",
       "  'story': True,\n",
       "  'regarding': True,\n",
       "  'crew': True,\n",
       "  'of': True,\n",
       "  'tugboat': True,\n",
       "  'comes': True,\n",
       "  'across': True,\n",
       "  'deserted': True,\n",
       "  'russian': True,\n",
       "  'tech': True,\n",
       "  'ship': True,\n",
       "  'has': True,\n",
       "  'strangeness': True,\n",
       "  'to': True,\n",
       "  'when': True,\n",
       "  'they': True,\n",
       "  'kick': True,\n",
       "  'power': True,\n",
       "  'back': True,\n",
       "  'on': True,\n",
       "  'little': True,\n",
       "  'do': True,\n",
       "  'know': True,\n",
       "  'within': True,\n",
       "  'going': True,\n",
       "  'for': True,\n",
       "  'gore': True,\n",
       "  'bringing': True,\n",
       "  'few': True,\n",
       "  'action': True,\n",
       "  'sequences': True,\n",
       "  'here': True,\n",
       "  'there': True,\n",
       "  ',': True,\n",
       "  'virus': True,\n",
       "  'still': True,\n",
       "  'feels': True,\n",
       "  'very': True,\n",
       "  'empty': True,\n",
       "  'like': True,\n",
       "  'all': True,\n",
       "  'flash': True,\n",
       "  'no': True,\n",
       "  'substance': True,\n",
       "  'we': True,\n",
       "  'don': True,\n",
       "  't': True,\n",
       "  'why': True,\n",
       "  'was': True,\n",
       "  'really': True,\n",
       "  'out': True,\n",
       "  'middle': True,\n",
       "  'nowhere': True,\n",
       "  'origin': True,\n",
       "  'what': True,\n",
       "  'took': True,\n",
       "  'over': True,\n",
       "  'just': True,\n",
       "  'big': True,\n",
       "  'pink': True,\n",
       "  'flashy': True,\n",
       "  'thing': True,\n",
       "  'hit': True,\n",
       "  'mir': True,\n",
       "  'course': True,\n",
       "  'donald': True,\n",
       "  'sutherland': True,\n",
       "  'is': True,\n",
       "  'stumbling': True,\n",
       "  'around': True,\n",
       "  'drunkenly': True,\n",
       "  'throughout': True,\n",
       "  '\"': True,\n",
       "  'hey': True,\n",
       "  'let': True,\n",
       "  'chase': True,\n",
       "  'these': True,\n",
       "  'people': True,\n",
       "  'with': True,\n",
       "  'some': True,\n",
       "  'robots': True,\n",
       "  'acting': True,\n",
       "  'below': True,\n",
       "  'average': True,\n",
       "  'even': True,\n",
       "  'from': True,\n",
       "  'likes': True,\n",
       "  'you': True,\n",
       "  're': True,\n",
       "  'more': True,\n",
       "  'likely': True,\n",
       "  'get': True,\n",
       "  'her': True,\n",
       "  'work': True,\n",
       "  'halloween': True,\n",
       "  'h20': True,\n",
       "  'wasted': True,\n",
       "  'well': True,\n",
       "  'he': True,\n",
       "  'real': True,\n",
       "  'star': True,\n",
       "  'are': True,\n",
       "  'stan': True,\n",
       "  'winston': True,\n",
       "  'robot': True,\n",
       "  'design': True,\n",
       "  'schnazzy': True,\n",
       "  'cgi': True,\n",
       "  'occasional': True,\n",
       "  'good': True,\n",
       "  'shot': True,\n",
       "  'picking': True,\n",
       "  'into': True,\n",
       "  'someone': True,\n",
       "  'brain': True,\n",
       "  'so': True,\n",
       "  'if': True,\n",
       "  'body': True,\n",
       "  'parts': True,\n",
       "  'turn': True,\n",
       "  'your': True,\n",
       "  'otherwise': True,\n",
       "  'pretty': True,\n",
       "  'much': True,\n",
       "  'sunken': True},\n",
       " 'neg')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negreviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate our algorithm at a later step, we will need to split the dataset into training and test set. \n",
    "\n",
    "Here, we will use 75% of the data as the training set, and the rest as the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "negsplit = int(len(negreviews)*0.75)\n",
    "possplit = int(len(posreviews)*0.75)\n",
    "\n",
    "trainingset = negreviews[:negsplit] + posreviews[:possplit]\n",
    "testset = negreviews[negsplit:] + posreviews[possplit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier training method expects to be given a list of tokens in the form of [(feats, label)] where feats is a feature dictionary and label is the classification label. In our case, feats will be of the form {word: True} and label will be one of ‘pos’ or ‘neg’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n"
     ]
    }
   ],
   "source": [
    "print('train on %d instances, test on %d instances' % (len(trainingset), len(testset)))\n",
    "classifier = NaiveBayesClassifier.train(trainingset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accuracy evaluation, we can use nltk.classify.util.accuracy with the test set as the gold standard.\n",
    " \n",
    "Accuracy is described as follows (taken from NLTK documentation): Given a list of reference values and a corresponding list of test values, return the fraction of corresponding values that are equal. \n",
    "\n",
    "In particular, return the fraction of indices\n",
    "    ``0<i<=len(test)`` such that ``test[i] == reference[i]``.\n",
    "\n",
    "    :type reference: list\n",
    "    :param reference: An ordered list of reference values.\n",
    "    :type test: list\n",
    "    :param test: A list of values to compare against the corresponding  reference values.\n",
    "    :raise ValueError: If ``reference`` and ``length`` do not have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.728\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, NLTK allows us to see the most useful features:\n",
    "\n",
    "According to NLTK documentation, the most_informative_features() returns a list of the 'most informative' features used by the classifier.  For the purpose of this function, the informativeness of a feature ``(fname,fval)`` is equal to the highest value of P(fname=fval|label), for any label, divided by the lowest value of P(fname=fval|label), for any label:\n",
    "\n",
    "        |  max[ P(fname=fval|label1) / P(fname=fval|label2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
