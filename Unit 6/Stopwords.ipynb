{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may choose to completely ignore some words called stopwords, i.e. very frequent words such as \"the\" and \"I\". This can be done is several ways. One way could be to sort the vocabulary (i.e. words in data) by frequency in the training set, and define the top 10-100 vocabulary entries as stop words, or alternatively by using one of the many pre-defined stop word lists available online or by NLTK. Then every instance of these stop words are simply removed from both training and test documents as if they had never occured. In most existing text classification applications, however, using a stop word list might not improve performance. Let's see an example.\n",
    "\n",
    "For this example, we will use the stop word list from NLTK. You can import it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will need to write a function, which takes as input some text called \"words\" and output a dictionary which maps a feature name (word) to True if the word exists in the data, similarly to the previous example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "def features_without_stopwords(words):\n",
    "    return dict([(word, True) for word in words if word not in stopset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, this is just the same code as previously. The only thing that changes is the feature extraction method, \n",
    "#which is user specified.\n",
    "def evaluate_classifier(feature_extraction):\n",
    "    \n",
    "    negids = movie_reviews.fileids('neg')\n",
    "    posids = movie_reviews.fileids('pos')\n",
    " \n",
    "    negreviews = [(feature_extraction(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "    posreviews = [(feature_extraction(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "    negsplit = int(len(negreviews)*0.75)\n",
    "    possplit = int(len(posreviews)*0.75)\n",
    "\n",
    "    trainingset = negreviews[:negsplit] + posreviews[:possplit]\n",
    "    testset = negreviews[negsplit:] + posreviews[possplit:]\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(trainingset)\n",
    " \n",
    "    print('accuracy:', nltk.classify.util.accuracy(classifier, testset))\n",
    "    classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can evaluate the following classifier as follows. Note that this code can take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.724\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(features_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Are stopwords important for sentiment analysis? What do you think it happened here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
